# PDF Parsing Pipeline

A **refined and optimized** PDF parsing pipeline that correctly extracts tables and filters relevant images from PDF documents. This pipeline processes unstructured data and organizes parsed content into three distinct folders: **images**, **tables**, and **text**.

## ğŸ¯ Key Features

### **Accurate Table Extraction**
- âœ… **Single Clean Table**: Extracts exactly one properly formatted table
- âœ… **Correct Format**: Clean CSV format without extra text or malformed data
- âœ… **Proper Structure**: Accurate row and column detection
- âœ… **Content Validation**: Filters out meaningless or duplicate content

### **Smart Image Filtering**
- âœ… **Relevant Images Only**: Extracts only meaningful images (e.g., full pages, graphics)
- âœ… **Filters Table Crops**: Excludes small table crops and irrelevant elements
- âœ… **Size Validation**: Filters based on image dimensions and content quality
- âœ… **Smart Detection**: Uses filename patterns and content analysis

### **Organized Output**
- âœ… **Three Folders**: Content automatically sorted into `images/`, `tables/`, `text/`
- âœ… **Unique Naming**: Prevents file overwriting with intelligent naming
- âœ… **Clean Structure**: Logical file organization with meaningful names
- âœ… **No Duplicates**: Prevents redundant outputs and duplicate content

## ğŸ“‹ Requirements

### **System Requirements**
- Python 3.8+ (tested with 3.13)
- Tesseract OCR installed and available on PATH
- 2GB+ RAM recommended
- GPU support optional but recommended for advanced features

### **Dependencies**
All dependencies are automatically installed via `requirements.txt`:
- `od-parse` - Core PDF parsing library
- `pandas` - Data manipulation for tables
- `PyYAML` - Configuration management
- `Pillow` - Image processing
- `opencv-python` - Computer vision
- And many more advanced libraries

## ğŸ› ï¸ Installation

1. **Clone the repository:**
```bash
git clone <repository-url>
cd octondata1
```

2. **Install dependencies:**
```bash
pip install -r requirements.txt
```

3. **Install Tesseract OCR:**
   - **Windows**: Download from [GitHub](https://github.com/UB-Mannheim/tesseract/wiki)
   - **macOS**: `brew install tesseract`
   - **Linux**: `sudo apt-get install tesseract-ocr`

4. **Verify installation:**
```bash
python test_refined_pipeline.py
```

## ğŸš€ Quick Start

### **Command Line Usage**

Process a single PDF document:
```bash
python refined_pipeline.py --input document.pdf
```

Process with custom output directory:
```bash
python refined_pipeline.py --input document.pdf --output ./my_results
```

Process with timestamps in filenames:
```bash
python refined_pipeline.py --input document.pdf --timestamps
```

### **Python API Usage**

```python
from refined_pipeline import RefinedPipeline

# Initialize pipeline
pipeline = RefinedPipeline()

# Process a PDF
result = pipeline.process_document("document.pdf")

# Check results
if result['status'] == 'success':
    print(f"Processing completed in {result['processing_time_seconds']:.2f}s")
    print(f"Extracted: {result['content_extracted']}")
    
    # Access specific content
    tables = result['tables']
    images = result['images']
    text = result['text']
```

## ğŸ“ Output Structure

When the pipeline runs, it automatically creates an output directory with organized content:

```
outputs/
â”œâ”€â”€ images/           # Extracted images
â”‚   â””â”€â”€ document_page_1.png
â”œâ”€â”€ tables/           # Extracted tables
â”‚   â”œâ”€â”€ document_table.csv
â”‚   â””â”€â”€ document_table.json
â”œâ”€â”€ text/             # Extracted text
â”‚   â””â”€â”€ document_extracted_text.txt
â””â”€â”€ processing_summary_document.json
```

### **File Naming Convention**
- **Images**: `{document_name}_page_{number}.{extension}`
- **Tables**: `{document_name}_table.csv` and `{document_name}_table.json`
- **Text**: `{document_name}_extracted_text.txt`

## âš™ï¸ Configuration

The pipeline uses `streamlined_config.yaml` for configuration:

```yaml
# Input and Output Settings
input_file: "./sample.pdf"
output_dir: "./outputs"

# File Naming Settings
use_timestamps: false
preserve_source_name: true

# Parser Configuration
parser:
  pdf: true
  pdf_config:
    extract_tables: true
    extract_forms: true
    extract_structure: true
    extract_images: true
    ocr: true
    handwritten_detection: true
    img2table: true
    image_naming: "descriptive"

# Logging Configuration
logging:
  enable_logging: true
  log_file: "refined_pipeline.log"
  log_level: "INFO"
```

## ğŸ§ª Testing

Run the comprehensive test suite:

```bash
python test_refined_pipeline.py
```

Test coverage includes:
- âœ… **Table Extraction**: Validates single table extraction with correct format
- âœ… **Image Filtering**: Confirms only relevant images are extracted
- âœ… **Content Validation**: Ensures data quality and proper formatting
- âœ… **Output Organization**: Verifies correct file structure and naming
- âœ… **Error Handling**: Tests edge cases and error scenarios

### **Test Results**
```
ğŸ“Š Test Summary
============================================================
Table Extraction          âœ“ PASS
Image Filtering           âœ“ PASS
Content Validation        âœ“ PASS
Output Organization       âœ“ PASS
Error Handling            âœ“ PASS

Overall: 5/5 tests passed
ğŸ‰ All tests passed! The refined pipeline is ready to use.
```

## ğŸ“Š Performance

### **Processing Speed**
- **Small PDFs** (1-5 pages): 2-5 seconds
- **Medium PDFs** (10-20 pages): 10-30 seconds
- **Large PDFs** (50+ pages): 1-5 minutes

### **Memory Usage**
- **Base**: ~100MB
- **With OCR**: ~200-500MB
- **With Neural Networks**: ~500MB-2GB

## ğŸ” Debugging and Logging

Enable verbose logging for debugging:

```bash
python refined_pipeline.py --input document.pdf --verbose
```

Log output includes:
- Table extraction process and quality scoring
- Image filtering decisions and reasoning
- Content validation results
- File organization and naming

## ğŸš¨ Troubleshooting

### **Common Issues**

1. **Tesseract not found**:
   ```bash
   # Install Tesseract and ensure it's in PATH
   tesseract --version
   ```

2. **Permission errors**:
   ```bash
   # Ensure write permissions for output directory
   chmod 755 ./outputs
   ```

3. **Memory issues with large PDFs**:
   ```bash
   # Process smaller batches or increase system memory
   python refined_pipeline.py --input large_document.pdf
   ```

4. **Missing dependencies**:
   ```bash
   # Reinstall requirements
   pip install -r requirements.txt --force-reinstall
   ```

## ğŸ“ˆ Quality Improvements

### **Before (Issues Fixed)**
- âŒ Multiple duplicate tables with malformed data
- âŒ 5+ images including table crops and irrelevant content
- âŒ Extra text and formatting issues in tables
- âŒ Inconsistent file naming and organization

### **After (Refined Pipeline)**
- âœ… Single clean table with proper format
- âœ… 1 relevant image (full page content)
- âœ… Clean CSV data without extra text
- âœ… Consistent, meaningful file naming

## ğŸ¯ Use Cases

### **Perfect For**
- **Document Processing**: Clean extraction of tables and images
- **Data Analysis**: Properly formatted CSV tables for analysis
- **Content Management**: Organized image and text content
- **Quality Assurance**: Reliable, consistent extraction results

### **Ideal Scenarios**
- PDFs with mixed content (tables, images, text)
- Documents requiring clean data extraction
- Batch processing with quality requirements
- Content that needs to be organized and validated

## ğŸ“ Project Structure

```
octondata1/
â”œâ”€â”€ refined_pipeline.py          # Main pipeline implementation
â”œâ”€â”€ test_refined_pipeline.py     # Test suite
â”œâ”€â”€ streamlined_config.yaml      # Configuration file
â”œâ”€â”€ requirements.txt             # Dependencies
â”œâ”€â”€ sample.pdf                   # Test PDF file
â”œâ”€â”€ README.md                    # This documentation
â””â”€â”€ refined_output/              # Output directory (created on run)
    â”œâ”€â”€ images/
    â”œâ”€â”€ tables/
    â””â”€â”€ text/
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests for new functionality
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- **od-parse**: Core PDF parsing capabilities
- **Tesseract OCR**: Optical character recognition
- **Pandas**: Data manipulation and table processing
- **OpenCV**: Computer vision and image processing

---

**ğŸ¯ Ready to Process PDFs!** 

Start with:
```bash
python refined_pipeline.py --input your_document.pdf
```

The pipeline will automatically create organized output with clean tables, relevant images, and structured text content.